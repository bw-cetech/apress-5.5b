{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNNs-Forecasting.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Stock Price Forecasting with RNNs"
      ],
      "metadata": {
        "id": "ROBGCawdqmzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GOAL: use previous day stock prices to forecast foreward stock prices for 60 days into the future"
      ],
      "metadata": {
        "id": "VThw1FhGquyZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://responsive.fxempire.com/v7/_fxempire_/2021/04/Stock-Market-2-2.jpg?func=cover&q=70&width=500\" alt=\"Stock Price Demo\" width=\"300\" height=150/>"
      ],
      "metadata": {
        "id": "9ioWGqp0rEs7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: FX Empire"
      ],
      "metadata": {
        "id": "4l9seTqFsYtM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Libraries"
      ],
      "metadata": {
        "id": "VJzGMqNcsrde"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlN00QhTqffO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#to plot within notebook\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#importing required libraries\n",
        "from sklearn.preprocessing import MinMaxScaler #for normalizing \"skewed\" data\n",
        "\n",
        "from keras.models import Sequential # library module for \"layering\" in python code for each NN layer\n",
        "from keras.layers import Dense, Dropout, LSTM # LSTM (specialised RNN) is the only different module we need from a CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# config - display plots inline\n",
        "%matplotlib inline\n",
        "\n",
        "#setting figure size\n",
        "from matplotlib.pylab import rcParams\n",
        "rcParams['figure.figsize'] = 20,10 # figure size in inches"
      ],
      "metadata": {
        "id": "tR3FbmD5tH4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Data Import & EDA"
      ],
      "metadata": {
        "id": "-TNV1K0btckf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "to add a data file to Colab use the folder on the LHS, go up a level to the main directory and choose the \"Content\" folder. Drag and drop the data file into that folder. Right click on the file uploaded and select \"copy path\""
      ],
      "metadata": {
        "id": "TmyLeoz8tf42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise - see if you can import the stock price data using the instruction above\n",
        "\n"
      ],
      "metadata": {
        "id": "P6OW0UTXtbGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "8rrF_OHRzZq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Unuezxoczbd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Wrangling / Formatting"
      ],
      "metadata": {
        "id": "Xk8Sd7fGzsDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python reads \"Date\" column as a string (object). We need to convert this to a pandas datetime format before we set up our RNN. But we also need to keep the raw format as plotting dates requires \"Date\" to be in its original string format"
      ],
      "metadata": {
        "id": "iCKgKKwyzw_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setting index as date values\n",
        "df['Date'] = pd.to_datetime(df.Date,format='%Y-%m-%d') # Y is 4 digit year, y would be 2 digit year\n",
        "df.index = df['Date'] # set Date column as an index\n",
        "\n",
        "# sort the data so that Date is in ascending order\n",
        "data = df.sort_index(ascending=True, axis=0)\n",
        "\n",
        "# isolate Date and Close columns\n",
        "# NB this is initially empty\n",
        "new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])\n",
        "\n",
        "# copying each rows in our source data into the two column version of our data (called new_data)\n",
        "for i in range(0,len(data)):\n",
        "    new_data['Date'][i] = data['Date'][i]\n",
        "    new_data['Close'][i] = data['Close'][i]\n",
        "\n",
        "new_data.head()"
      ],
      "metadata": {
        "id": "g1IuRoeFzhlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aside \n",
        "data.head()"
      ],
      "metadata": {
        "id": "gBnnZGXJ1QkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Wrangling - Data Partitioning"
      ],
      "metadata": {
        "id": "Y63QKIJQ1mh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.index = new_data.Date # set the Date column of \"new_data\" as the index\n",
        "new_data.head()"
      ],
      "metadata": {
        "id": "RPYl8pm61UFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop the extra Date column\n",
        "new_data.drop(\"Date\", axis = 1, inplace = True)\n",
        "new_data.head() # check"
      ],
      "metadata": {
        "id": "6an-Ijen12sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a training and test set using an 80/20 split\n",
        "\n",
        "dataset = new_data.values # copying the values from the new_data dataframe\n",
        "\n",
        "# we set training data as the first 80% of rows, and test data as the remaining 20%\n",
        "train = dataset[0:int(len(new_data)*0.8-1),:] # from rows 0 to 987 (exclusive)\n",
        "test = dataset[int(len(new_data)*0.8-1):,:] # from row 987 to the end (row 1234)"
      ],
      "metadata": {
        "id": "Dwv99eBw2EtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# post checks\n",
        "len(train)"
      ],
      "metadata": {
        "id": "CY2PeuzC3u5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "987 is 80% of the original data size (1235 rows)"
      ],
      "metadata": {
        "id": "gSkzg_7v4DKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(test)\n"
      ],
      "metadata": {
        "id": "ALTYhm5f3zT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise - scale the data so that the stock prices are between 0 and 1\n",
        "# use MinMaxScaler and apply to \"dataset\"\n"
      ],
      "metadata": {
        "id": "OpRCr0QE4JnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepare the data for Recurrent Neural Network"
      ],
      "metadata": {
        "id": "3xGgxEAV6dvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for RNNs (or LSTMs) we use previous time steps as additional \"features\""
      ],
      "metadata": {
        "id": "9ZeqjJR56kyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add the last 60 time buckets as fetures to our training set\n",
        "x_train, y_train = [], [] # initialisation as empty lists\n",
        "\n",
        "# loop thru the training set (starting from the 60th time step)\n",
        "for i in range(60, len(train)):\n",
        "  x_train.append(scaled_data[i-60:i,0]) # features are the last 60 time steps (multi-column)\n",
        "  y_train.append(scaled_data[i,0]) # target is just the current time step (single-column)\n",
        "\n",
        "# convert to numpy array format\n",
        "x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "\n",
        "# create a 3D tensor for the RNN network\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"
      ],
      "metadata": {
        "id": "_bCq5emh6XPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape # check tensor dimensions"
      ],
      "metadata": {
        "id": "JpCZ3_ay8Mcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fit LSTM Model"
      ],
      "metadata": {
        "id": "WPw9H3Mb8Zai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise - try on your own before viewing solution below\n",
        "\n",
        "# a) create / define an LSTM network (STEP 1)\n",
        "# b) compile (STEP 2) the model using adam optimization with MSE loss\n",
        "# c) fit the data to the model and train (STEP 3)"
      ],
      "metadata": {
        "id": "9wW8LUau8PxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xWOxMw9Wj5hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "blQ2GEpSj8iO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S5CfZ8cqj8k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6yprpIGXj8o2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a) create / define an LSTM network (STEP 1)\n",
        "model = Sequential() # TF sequential model\n",
        "\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(x_train.shape[1], 1))) # first hidden layer BASELINE\n",
        "#model.add(LSTM(50, activation='tanh', return_sequences=True, input_shape=(x_train.shape[1], 1))) # b) rerun the model with a different activation function (tanh)\n",
        "model.add(LSTM(50)) # input shape taken from previous hidden layer\n",
        "model.add(Dense(1)) # single hidden layer of LSTM units"
      ],
      "metadata": {
        "id": "rEJkNVHX-esx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# b) compile (STEP 2) the model using adam optimization with MSE loss\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "TTymsu-y_Vbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c) fit the data to the model and train (STEP 3)\n",
        "\n",
        "batch_size = 1 # baseline\n",
        "#batch_size = 10 # a) rerun the model with a different batch size and compare RMS error\n",
        "\n",
        "model.fit(x_train, \n",
        "          y_train, \n",
        "          epochs=1, \n",
        "          batch_size=batch_size, \n",
        "          verbose=1) # verbose = 1 gives us a bit more info when the training process runs"
      ],
      "metadata": {
        "id": "ymj6_L9z_aNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Evaluation / Predictions"
      ],
      "metadata": {
        "id": "Iw0ILShukQoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# wrangle the test data in the same way as the training data\n",
        "\n",
        "# get data from 60 time steps b4 test set starts\n",
        "inputs = new_data[len(new_data) - len(test) - 60:].values # everything in our new_data \n",
        "\n",
        "# dataframe from row number (1235 - 248 - 60 = 927) to the end (i.e. row 1234) - so 248+60 rows = 308\n",
        "inputs = inputs.reshape(-1,1) # -1 means use the number of rows in the source variable (input)\n",
        "inputs = scaler.transform(inputs) # we need to scale again as model was trained on scaled data\n",
        "\n",
        "# we start from row 60 of the TEST set\n",
        "x_test = []\n",
        "for i in range(60, inputs.shape[0]):\n",
        "    x_test.append(inputs[i-60:i,0]) # gather up the last 60 time steps for each of the test set timesteps\n",
        "x_test = np.array(x_test) # convert the actual test data to a numpy array\n",
        "\n",
        "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1], 1)) # convert to 3D numpy array for predicting\n",
        "pricePred = model.predict(x_test) # predict our stock price for next time step\n",
        "\n",
        "#### POST PROCESS - we need to \"unscale\" the test set in order to plot the data below\n",
        "# wrangle Data back to original format (unscaled) for plotting\n",
        "# (reverse process)\n",
        "pricePred = scaler.inverse_transform(pricePred) # reverse scale back into original units"
      ],
      "metadata": {
        "id": "TIvwYHx2_3Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# have a look at model performance \n",
        "# RMS = sqaure root of the average square error b/ w actual (test) and forecasted stock prices (pricePred)\n",
        "\n",
        "rms = np.sqrt(np.mean(np.power(test-pricePred,2)))\n",
        "rms"
      ],
      "metadata": {
        "id": "yPtSyGAulOgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "above value should be compared with our average stock price..."
      ],
      "metadata": {
        "id": "6To9ZzeCl5LW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# average (actual) stock price \n",
        "new_data[\"Close\"].mean()"
      ],
      "metadata": {
        "id": "R8sM-q2El2nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "our RMS error (residual) is about 12/169 = 7%"
      ],
      "metadata": {
        "id": "BTILubnTmL_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualise our Forecast"
      ],
      "metadata": {
        "id": "meZ2hEPjnHEW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we need to do some further wrangling to get our data into the correct format to plot on a time series matplot chart"
      ],
      "metadata": {
        "id": "QhUgPJEpnL-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We plot the actual stock prices against our predictions\n",
        "# and we colour the training set, test set and our predictions differently\n",
        "\n",
        "plt.figure(figsize=(10, 7)) # inches\n",
        "\n",
        "# plot the actual stock price time series chart against our predictions\n",
        "\n",
        "# re-defining the training set, our test set and our predictions for the chart we are about to show\n",
        "train_new = new_data[:int(len(new_data)*0.8-1)] # up to row number 80% of total rows in new_data\n",
        "test_new = new_data[int(len(new_data)*0.8-1):] # from row number 80% of total rows to the end\n",
        "test_new[\"Predictions\"] = pricePred # copy our predicted stock prices\n",
        "\n",
        "plt.rcParams.update({'font.size': 15})\n",
        "\n",
        "plt.plot(train_new[\"Close\"]) # plot the training set data\n",
        "plt.plot(test_new[[\"Close\",\"Predictions\"]]) # plot the test set stock prices and our predictions\n",
        "# NB in line above we \"combine\" actual test stock prices and predictions \n",
        "# ON THE SAME LINE of the chart\n",
        "\n",
        "plt.title(\"TATA Stock Price - RNN forecasting comparison\")\n",
        "\n",
        "plt.legend([\"train\",\"test\",\"prediction\"])"
      ],
      "metadata": {
        "id": "9C9blW1mmDpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise - see if you can\n",
        "\n",
        "# a) make the plot bigger\n",
        "# b) decrease the axes font\n",
        "# c) change the legend to show train (80%), test (20%)"
      ],
      "metadata": {
        "id": "UrSFRf0nnsDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We plot the actual stock prices against our predictions\n",
        "# and we colour the training set, test set and our predictions differently\n",
        "\n",
        "plt.figure(figsize=(12, 8)) # a) make the plot bigger\n",
        "\n",
        "# plot the actual stock price time series chart against our predictions\n",
        "\n",
        "# re-defining the training set, our test set and our predictions for the chart we are about to show\n",
        "train_new = new_data[:int(len(new_data)*0.8-1)] # up to row number 80% of total rows in new_data\n",
        "test_new = new_data[int(len(new_data)*0.8-1):] # from row number 80% of total rows to the end\n",
        "test_new[\"Predictions\"] = pricePred # copy our predicted stock prices\n",
        "\n",
        "plt.rcParams.update({'font.size': 10}) # b) decrease the axes font\n",
        "\n",
        "plt.plot(train_new[\"Close\"]) # plot the training set data\n",
        "plt.plot(test_new[[\"Close\",\"Predictions\"]]) # plot the test set stock prices and our predictions\n",
        "# NB in line above we \"combine\" actual test stock prices and predictions \n",
        "# ON THE SAME LINE of the chart\n",
        "\n",
        "plt.title(\"TATA Stock Price - RNN forecasting comparison\")\n",
        "\n",
        "plt.legend([\"train 80%\",\"test 20%\",\"prediction\"])"
      ],
      "metadata": {
        "id": "rvZrmN16r503"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise (scenario runs)\n",
        "# a) rerun the model with a different batch size and compare RMS error\n",
        "# b) rerun the model with a different activation function (tanh)"
      ],
      "metadata": {
        "id": "yaG1b8aDoYvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9p_KASf4saSW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}